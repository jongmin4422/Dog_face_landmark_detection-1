{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18d5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import resnet_V2\n",
    "import data_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c035a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67dff59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = keras.losses.MeanSquaredError()\n",
    "ce = keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33920057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    y_class_true = y_true[:, 0:133]\n",
    "    y_class_pred = y_pred[:, 0:133]\n",
    "    \n",
    "    y_point_true = y_true[:, 133:]\n",
    "    y_point_pred = y_pred[:, 133:]\n",
    "    \n",
    "    class_loss = ce(y_class_true, y_class_pred)\n",
    "    ce_loss = mse(y_point_true, y_point_pred)\n",
    "    \n",
    "    return 0.5 * ce_loss + 0.5 * class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19d2aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res_net_encoder_2 (ResNetEncode (None, 16, 16, 128)  1479600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32768)        0           res_net_encoder_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "branch1_class (Dense)           (None, 133)          4358277     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch2_landmark (Dense)        (None, 16)           524304      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 149)          0           branch1_class[0][0]              \n",
      "                                                                 branch2_landmark[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 6,362,181\n",
      "Trainable params: 6,356,821\n",
      "Non-trainable params: 5,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size= 256\n",
    "batch_size=16\n",
    "\n",
    "ae = resnet_V2.ResNetAE()\n",
    "ae.load_weights('./trained_ckpt/model_5.ckpt')\n",
    "encoder = ae.encoder\n",
    "input = keras.layers.Input(shape=(256,256,3))\n",
    "\n",
    "encoder_output = encoder(input)\n",
    "flatten = keras.layers.Flatten()(encoder_output)\n",
    "\n",
    "branch1_class = keras.layers.Dense(133,activation='softmax',name='branch1_class')(flatten)\n",
    "\n",
    "branch2_landmark = keras.layers.Dense(16,name='branch2_landmark')(flatten)\n",
    "\n",
    "out= keras.layers.concatenate([branch1_class,branch2_landmark])       # concatnate?\n",
    "\n",
    "model = keras.models.Model(input, out)\n",
    "model.compile(loss=custom_loss,\n",
    "              optimizer='adam'\n",
    "              )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35e0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = data_util.get_cu_dataset(train_type='class', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d80050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 256, 256, 3)\n",
      "(16, 149)\n"
     ]
    }
   ],
   "source": [
    "for i in ds.take(1):\n",
    "    print(i[0].shape)\n",
    "    print(i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3cb12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_size = len(list(ds))\n",
    "ds_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b60609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * ds_size)\n",
    "val_size = int(0.15 * ds_size)\n",
    "test_size = int(0.15 * ds_size)\n",
    "\n",
    "train_ds = ds.take(train_size)\n",
    "test_ds = ds.skip(train_size)\n",
    "val_ds = test_ds.skip(val_size)\n",
    "test_ds = test_ds.take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2117e120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334, 73, 71)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_ds)), len(list(val_ds)), len(list(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cde5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = './ckpt/pre_multi'\n",
    "callbacks_list = [\n",
    "    # accuracy 기준 가장 높은 모델의 weight 저장\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = ckpt_path,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    # EarlyStopping\n",
    "    # tf.keras.callbacks.EarlyStopping(\n",
    "    #    monitor='val_loss',\n",
    "    #    mode='min',\n",
    "    #    verbose=1, \n",
    "    #    patience=20\n",
    "    # )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26380816",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
